add2 <- function(x, y) {
x + y
}
add2(5,6)
View(add2)
function(x, y) {
x + y
}
above10 <- function(x) {
use  <- x > 10
x[use]
}
above <- function(x, n){
use <- x > n
x[use]
}
x <- 1:20
above(x, 12)
args(above2)
arg(above2)
args(paste)
args(cat)
args(plot)
install.packages("kernlab")
?order
library(kernlab)
library(caret)
install.packages("quantreg")
library(caret)
data(spam)
inTrain<-createDataPartition(y=spam$type, p=0.75, list=F)
training<-spam[inTrain,]
testing<-spam[-inTrain,]
dim(training)
head(spam)
head(spam)
training
testing
inTrain
set.seed(32343)
head(spam)
type$spam
spam[, "type"]
if (spam[, "type"]==nonspam) {}
count(spam, "type")
library(plyr)
count(spam, "type")
modelFit <- train(type ~.,data=training, method="glm")
library(caret)
library(kernlab)
modelFit <- train(type ~.,data=training, method="glm")
install.packages(e1071)
install.packages("e1071")
modelFit <- train(type ~.,data=training, method="glm")
warnings()
modelFit
modelFit$finalModel
predictions <- predict(modelFit, newdata=testing)
predictions
confusionMatrix(predictions, testing$type)
inTrain<-createDataPartition(y=spam$type, p=0.75, list=FALSE)
dim(testing)
dim(inTrain)
dim(-inTrain)
install.packages("ISLR")
library(ISLR); library(ggplot2 ); library(caret)
date(Wage)
data(Wage)
str(Wage)
summary(Wage)
inTrain <- createDataPartition(y=Wage$wage, p=0.7, list=F)
training <- Wage[inTrain,]
testing <- Wage[-inTrain,]
featurePlot(x=training[, c("age", "education", "jobclass")],
y=training$wage, plot="pairs")
qplot(age, wage, color=jobclass, data=training)
qq <- qplot(age, wage, color=education, data=training)
qq + geom_smooth(method='lm', formula=y~x)
library(Hmisc)
install.packages("Hmisc")
library(Hmisc)
cutWage<-cut2(training$wage, g=3)
table(cutWage)
cutWage<-cut2(training$wage, g=10)
table(cutWage)
p1 <-qplot(cutWage, age, data=training, fill=cutWage, geom=c("boxplot"))
p1
p1 <-qplot(cutWage, age, data=training, fill=cutWage, geom=c("jitter", "boxplot"))
p1
p1 <-qplot(cutWage, age, data=training, fill=cutWage, geom=c("jitter", "boxplot"), alpha=0.6)
p1
library(AppliedPrideictiveModeling)
library(AppliedPredictiveModeling)
library(AppliedPredictiveModeling)
install.packages("AppliedPredictiveModeling")
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
?createDataPartition
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
hist(training$SuperPlasticizer)
hist(training$Superplasticizer)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
qplot(Superplasticizer, data=training)
ggplot(data=training, aes(x=Superplasticizer)) + geom_histogram() + theme_bw()
ss<-training[, grep("^IL", x=names(training))]
preProc <- preProcess(ss, method='pca', thresh=0.9, outcome=training$diagnosis)
preProc <- preProcess(ss, method='pca', thresh=0.9,
outcome=training$diagnosis)
ss <- training[,grep('^IL', x = names(training) )]
preProc <- preProcess(ss, method='pca', thresh=0.9,
outcome=training$diagnosis)
diagnosis
predictors
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p=3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
ss <- training[,grep('^IL', x = names(training) )]
preProc <- preProcess(ss, method='pca', thresh=0.9,
outcome=training$diagnosis)
preProc$rotation # 9
dim(diagnosis)
dim(predictors)
adData
str(adData)
summary(adData)
head(adData)
names(training)
ss <- training[,grep('^IL', x = names(training) )]
ss
?ggplot
?replicae
?replicate
?rexp
?cbind
?qqplot
install.packages("dgof")
?pnorm
?rexp
?geom_abline
?stat_function
?geom_curve
??geom_curve
??ggplot
?goodfit
??goodfit
library(cran)
install.packages(vcd)
install.packages('vcd')
?goodfit
??goodfit
install.packages("shiny")
setwd(Coursera_devdata)
dir()
setwd("Coursera_devdata" )
ls()
dir()
runApp()
??runApp
library(shiny)
runApp()
ls
dir()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
dir()
dir()
runApp("project")
setwd("project")
runApp("project")
setwd("..")
dir()
runApp("project")
runApp("project")
setwd("..")
dir()
runApp("RShiny")
runApp("RShiny")
runApp("RShiny")
setwd("Coursera_devdata")
runApp("project")
runApp("project")
runApp("project")
runApp("project")
install.packages("rCharts")
library(devtools)
install.packages("devtools")
install_github("ramnathv/rCharts@dev")
library(devtools)
install_github("ramnathv/rCharts@dev")
install.packages('base64enc')
library(base64enc)
install_github("ramnathv/rCharts@dev")
library(rCharts)
?rCharts
??rCharts
runApp("project")
library(maps)
install.packages("maps")
install.packages("mapproj")
runApp("project")
runApp("project")
runApp("project")
dir()
setwd("../..")
dir()
setwd("kafka")
runApp("RShiny")
runApp("RShiny")
setwd("Coursera_devdata")
runApp("project")
runApp("project")
runApp("project")
runApp("project")
runApp("project")
runApp("project")
runApp("project")
library(datasets)
runApp()
ls
dir()
setwd("project")
runApp()
